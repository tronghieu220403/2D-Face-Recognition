{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ-tpQT4NzwB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from dataset import create_image_path_ds, preprocess_image\n",
        "from OneM_tripless import build_txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-4HTJanDP40"
      },
      "outputs": [],
      "source": [
        "def create_ds(i):\n",
        "  positive_train_1 = create_image_path_ds(f'./lfw/lists/0{i}_train_same.txt','./lfw/faces_png/')\n",
        "  negative_train_1 = create_image_path_ds(f'./lfw/lists/0{i}_train_diff.txt','./lfw/faces_png/')\n",
        "  positive_test_1 = create_image_path_ds(f'./lfw/lists/0{i}_test_same.txt','./lfw/faces_png/')\n",
        "  negative_test_1 = create_image_path_ds(f'./lfw/lists/0{i}_test_diff.txt','./lfw/faces_png/')\n",
        "  train_ds = positive_train_1.concatenate(negative_train_1)\n",
        "  val_ds = positive_test_1.concatenate(negative_test_1)\n",
        "  return train_ds, val_ds\n",
        "def create_ds_1m():\n",
        "  positive_train_1 = create_image_path_ds(f'./train_same.txt','./siamese/')\n",
        "  negative_train_1 = create_image_path_ds(f'./train_diff.txt','./siamese/')\n",
        "  positive_test_1 = create_image_path_ds(f'./test_same.txt','./siamese/')\n",
        "  negative_test_1 = create_image_path_ds(f'./test_diff.txt','./siamese/')\n",
        "  train_ds = positive_train_1.concatenate(negative_train_1)\n",
        "  val_ds = positive_test_1.concatenate(negative_test_1)\n",
        "  return train_ds, val_ds\n",
        "# build_txt('same', './train_same.txt', 4000)\n",
        "# build_txt('diff', './train_diff.txt', 4000)\n",
        "# build_txt('same', './test_same.txt', 1000)\n",
        "# build_txt('diff', './test_diff.txt', 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YJ-Nze5NzwC"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds = create_ds(1)\n",
        "for i in range(2, 10):\n",
        "  train_ds_1, val_ds_1 = create_ds(i)\n",
        "  train_ds = train_ds.concatenate(train_ds_1)\n",
        "  val_ds = val_ds.concatenate(val_ds_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9wudmPXIKJe"
      },
      "outputs": [],
      "source": [
        "for i,j,k in train_ds.take(1):\n",
        "  print(i,j,k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pOlE0fjNzwD"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "def process(ds):\n",
        "  ds = ds.map(lambda x1, x2, y: (preprocess_image(x1), preprocess_image(x2), y))\n",
        "  ds = ds.map(lambda x1, x2, y: (preprocess_input(x1), preprocess_input(x2), y))\n",
        "  return ds\n",
        "\n",
        "train_ds = process(train_ds)\n",
        "val_ds = process(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2GlkJyiNzwD",
        "outputId": "af6e3736-8987-4fec-e0ea-073ee1c99b98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.float32, name=None))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = train_ds.shuffle(buffer_size=1024)\n",
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snRTKP-SNzwD"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(64)\n",
        "val_ds = val_ds.batch(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_qF1f1dNzwD"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(lambda x1,x2,y: ((x1,x2),y))\n",
        "val_ds = val_ds.map(lambda x1,x2,y: ((x1,x2),y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVUgSEqDNzwD"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "\n",
        "res50 = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling='avg',\n",
        "    classes=1000\n",
        ")\n",
        "\n",
        "for layer in res50.layers:\n",
        "    layer.trainable = False\n",
        "embedding = Sequential([\n",
        "        Model(inputs=res50.input, outputs=res50.layers[-2].output, name='res50_extractor'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(2048, activation='relu', name='fc_rd0'),\n",
        "        layers.BatchNormalization(name='fc_db_rd1'),\n",
        "        layers.Dense(512, activation='sigmoid', name='fc_rd1'),\n",
        "        layers.BatchNormalization(name='fc_db_rd2'),\n",
        "        layers.Dense(128, activation='sigmoid', name='fc_rd2'),\n",
        "        layers.LayerNormalization(name='fc_db_rd3', axis=1),\n",
        "    ])\n",
        "embedding.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq34sHGRNzwD"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class L1Dist(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "    def call(self, anchor_embedding, validation_embedding):\n",
        "        return tf.math.reduce_euclidean_norm(anchor_embedding - validation_embedding, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3WVlEe0NzwE",
        "outputId": "c8da6864-ff59-45ca-ddca-5178cf307080"
      },
      "outputs": [],
      "source": [
        "anchor_input = layers.Input(shape=(224,224,3), name='anchor_input')\n",
        "validation_input = layers.Input(shape=(224,224,3), name='validation_input')\n",
        "\n",
        "\n",
        "l1_layer = L1Dist(name='l1_distance')\n",
        "distances = l1_layer(embedding(anchor_input), embedding(validation_input))\n",
        "\n",
        "model = Model(inputs=[anchor_input, validation_input], outputs=distances)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJfncGyzNzwE"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgAhiO3iNzwE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "epochs = 5\n",
        "# train(train_ds, epochs)\n",
        "checkpoint = tf.train.Checkpoint(model)\n",
        "\n",
        "for i in range(10):\n",
        "  save_path = checkpoint.save('./tmp/training_checkpoints_lfw')\n",
        "  gc.collect()\n",
        "  print(save_path)\n",
        "  history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    batch_size=64\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bY0rXhVHCzi"
      },
      "outputs": [],
      "source": [
        "model.save('siamese_1M_2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmrek_2FZYT9"
      },
      "outputs": [],
      "source": [
        "img_a = preprocess_image('./WIN_20231231_04_09_40_Pro.jpg',(IMG_SIZE, IMG_SIZE))\n",
        "img_b = preprocess_image('./WIN_20231231_03_50_45_Pro.jpg',(IMG_SIZE, IMG_SIZE))\n",
        "img_c = preprocess_image('./WIN_20231231_04_15_02_Pro.jpg',(IMG_SIZE, IMG_SIZE))\n",
        "img_d = preprocess_image('./WIN_20231231_03_50_38_Pro.jpg',(IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "i_a = np.expand_dims(img_a, axis=0)\n",
        "i_b = np.expand_dims(img_b, axis=0)\n",
        "i_c = np.expand_dims(img_c, axis=0)\n",
        "i_d = np.expand_dims(img_d, axis=0)\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img_d)\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(img_b)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(img_c)\n",
        "plt.show()\n",
        "\n",
        "print(model.predict([i_b, i_a]))\n",
        "print(model.predict([i_a, i_c]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
